# Инструкция для тестирования N8N-AI-Starter-Kit в Visual Studio Code

## Обзор
N8N-AI-Starter-Kit — это самоуправляемая AI-среда, предназначенная для быстрого создания локальной среды разработки с использованием Docker Compose. Проект включает такие инструменты, как n8n (платформа автоматизации рабочих процессов), Ollama (для работы с большими языковыми моделями), Qdrant (векторная база данных) и Postgres (база данных). Ваша задача — проверить работоспособность проекта, убедившись, что все компоненты установлены, настроены и функционируют корректно.

## Предварительные требования
Перед началом убедитесь, что на вашем компьютере установлены:
- **Docker**: Для запуска контейнеров проекта.
- **Docker Compose**: Для управления многоконтейнерными приложениями Docker.
- **Git**: Для клонирования репозитория.
- **Visual Studio Code (VS Code)**: Для работы с файлами проекта и выполнения команд в терминале.

Также убедитесь, что ваша система соответствует аппаратным требованиям, особенно если вы планируете использовать GPU (например, Nvidia или AMD).

## Пошаговая инструкция по тестированию

### 1. Клонирование репозитория
- Откройте VS Code и запустите встроенный терминал (`Ctrl + `` или **Вид > Терминал**).
- Выполните следующую команду для клонирования репозитория:
  ```bash
  git clone https://github.com/sattva2020/N8N-AI-Starter-Kit.git
  ```
- Перейдите в директорию проекта:
  ```bash
  cd N8N-AI-Starter-Kit
  ```

### 2. Ознакомление с документацией проекта
- Откройте файл `README.md` в VS Code, чтобы изучить инструкции по установке и требования.
- Обратите внимание на любые специфические указания или конфигурации, которые могут отличаться от оригинального проекта N8N Self-hosted AI Starter Kit.

### 3. Настройка переменных окружения
- Проверьте наличие файла `.env` в директории проекта. Если он есть, убедитесь, что переменные, такие как `POSTGRES_USER`, `POSTGRES_PASSWORD` и `N8N_ENCRYPTION_KEY`, настроены правильно.
- Если файла `.env` нет, создайте его на основе шаблона из документации или оригинального репозитория.

### 4. Запуск Docker Compose
- В зависимости от вашего оборудования выполните соответствующую команду Docker Compose:
  - **Для CPU-only установок**:
    ```bash
    docker compose --profile cpu up
    ```
  - **Для пользователей с Nvidia GPU**:
    ```bash
    docker compose --profile gpu-nvidia up
    ```
  - **Для пользователей с AMD GPU на Linux**:
    ```bash
    docker compose --profile gpu-amd up
    ```
  - Если вы используете Mac с Apple Silicon (M1 или новее), GPU недоступен для Docker. В этом случае:
    - Запустите проект полностью на CPU с помощью профиля `cpu`.
    - Или установите Ollama локально на Mac и подключите её к n8n (см. документацию).

### 5. Проверка работоспособности сервисов
- После запуска Docker Compose проверьте состояние контейнеров:
  ```bash
  docker ps
  ```
- Убедитесь, что все сервисы запущены:
  - `n8n`
  - `ollama`
  - `qdrant`
  - `postgres`
- Если какой-либо сервис не запустился, проверьте логи для выявления ошибок:
  ```bash
  docker logs <container_name>
  ```

### 6. Доступ к интерфейсу n8n
- Откройте веб-браузер и перейдите по адресу `http://localhost:5678`.
- При первом запуске n8n запросит создание учетной записи. Следуйте инструкциям на экране.
- После входа вы должны увидеть панель управления n8n.

### 7. Тестирование рабочего процесса
- В интерфейсе n8n найдите предустановленные рабочие процессы или импортируйте пример, если он предоставлен в репозитории.
- Например, если есть демонстрационный процесс, откройте его и нажмите кнопку **Chat**, чтобы проверить взаимодействие с AI.
- Убедитесь, что Ollama завершил загрузку необходимых моделей (например, Llama 3.2). Проверьте логи контейнера Ollama.

### 8. Проверка AI-функциональности
- Протестируйте функции AI, запустив рабочий процесс, использующий Ollama для работы с языковыми моделями и Qdrant для векторного хранения.
- Например, если есть чат-бот с RAG (Retrieval-Augmented Generation), протестируйте его, чтобы убедиться, что он корректно извлекает данные и генерирует ответы.

### 9. Устранение типичных проблем
- **Проблемы с правами Docker**: Убедитесь, что Docker запущен с нужными разрешениями. На Linux может потребоваться `sudo` или добавление пользователя в группу Docker.
- **Конфликты портов**: Проверьте, что порты 5678 (n8n), 11434 (Ollama) и 6333 (Qdrant) не заняты другими приложениями.
- **Сетевые настройки**: Убедитесь, что сервисы могут взаимодействовать друг с другом. Проверьте настройки сети в файле `docker-compose.yml`.
- **Загрузка моделей**: Если используются определённые AI-модели, убедитесь, что они корректно загружены в Ollama.

### 10. Обращение к документации и поддержке
- Используйте `README.md` и другую документацию проекта для устранения неполадок.
- Обратитесь к форуму сообщества n8n или разделу Issues на GitHub оригинального репозитория для поиска решений.

## Заключение
Следуя этим шагам, вы сможете проверить работоспособность N8N-AI-Starter-Kit. Если все сервисы запускаются корректно, интерфейс n8n доступен, а рабочие процессы выполняются, проект считается рабочим. При возникновении проблем используйте логи и документацию для диагностики.